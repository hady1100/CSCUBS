{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "import re\n",
    "import string\n",
    "import\tmatplotlib\n",
    "import\tmatplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from datetime import date\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim import corpora\n",
    "%matplotlib\tinline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "CONST_WIKI_ALL = \"/home/hady/ml/cscubs18/datasets/wiki_3classes2.csv\"\n",
    "\n",
    "dataset = np.genfromtxt(CONST_WIKI_ALL, delimiter=\"|\\-/|\", skip_header=1,\n",
    "dtype={'names': ('klass', 'text'), 'formats': (np.int, '|S1000')})\n",
    "\n",
    "docs = dataset['text']\n",
    "labels = dataset['klass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the document\n",
    "fixed = []\n",
    "\n",
    "aux = 0\n",
    "for line in docs:\n",
    "    line = line.strip()\n",
    "    line = line.decode('cp1252')\n",
    "    fixed.extend([nltk.re.sub(r'[^\\x00-\\x7F]+', ' ', line)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_complete = fixed\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in doc_complete]\n",
    "\n",
    "doc_tfidf = []\n",
    "for line in doc_clean:\n",
    "    tmp = \"\"\n",
    "    i = 0\n",
    "    for word in line:\n",
    "        tmp = tmp + word\n",
    "        if i < (len(line) - 1):\n",
    "            tmp = tmp + \" \"\n",
    "    doc_tfidf.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 46542)\n"
     ]
    }
   ],
   "source": [
    "feature_extraction = TfidfVectorizer()\n",
    "data_iter = []\n",
    "aux = 0\n",
    "for t in doc_clean:\n",
    "    data_iter.extend(t)\n",
    "    \n",
    "feature_extraction = TfidfVectorizer()\n",
    "X = feature_extraction.fit_transform(doc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(decision_function_shape='ovo')\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC yields 0.33066666666666666\n",
      "0.33066666666666666\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "# print(predictions[:,1])\n",
    "print('ROC-AUC yields ' + str(accuracy_score(y_test, predictions)))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "# clf.predict(X_test)\n",
    "# y = bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
